{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Data paths\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Path追加\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import configargparse\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from args import get_config\n",
    "from data import Dataset\n",
    "from common.visulaizations import draw_bb\n",
    "\n",
    "import time\n",
    "import globalflow as gflow\n",
    "\n",
    "configs = get_config(\"-c ../../configs/mcftracker_notebook.ini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../../weights/old.pth\n",
      "Processing : 0 / 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/mmdet/datasets/utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000\n",
      "Processing : 1 / 105\n",
      "0001\n",
      "Processing : 2 / 105\n",
      "0002\n",
      "Processing : 3 / 105\n",
      "0003\n",
      "Processing : 4 / 105\n",
      "0004\n",
      "Processing : 5 / 105\n",
      "0005\n",
      "Processing : 6 / 105\n",
      "0006\n",
      "Processing : 7 / 105\n",
      "0007\n",
      "Processing : 8 / 105\n",
      "0008\n",
      "Processing : 9 / 105\n",
      "0009\n",
      "Processing : 10 / 105\n",
      "0010\n",
      "Processing : 11 / 105\n",
      "0011\n",
      "Processing : 12 / 105\n",
      "0012\n",
      "Processing : 13 / 105\n",
      "0013\n",
      "Processing : 14 / 105\n",
      "0014\n",
      "Processing : 15 / 105\n",
      "0015\n",
      "Processing : 16 / 105\n",
      "0016\n",
      "Processing : 17 / 105\n",
      "0017\n",
      "Processing : 18 / 105\n",
      "0018\n",
      "Processing : 19 / 105\n",
      "0019\n",
      "Processing : 20 / 105\n",
      "0020\n",
      "Processing : 21 / 105\n",
      "0021\n",
      "Processing : 22 / 105\n",
      "0022\n",
      "Processing : 23 / 105\n",
      "0023\n",
      "Processing : 24 / 105\n",
      "0024\n",
      "Processing : 25 / 105\n",
      "0025\n",
      "Processing : 26 / 105\n",
      "0026\n",
      "Processing : 27 / 105\n",
      "0027\n",
      "Processing : 28 / 105\n",
      "0028\n",
      "Processing : 29 / 105\n",
      "0029\n",
      "Processing : 30 / 105\n",
      "0030\n",
      "Processing : 31 / 105\n",
      "0031\n",
      "Processing : 32 / 105\n",
      "0032\n",
      "Processing : 33 / 105\n",
      "0033\n",
      "Processing : 34 / 105\n",
      "0034\n",
      "Processing : 35 / 105\n",
      "0035\n",
      "Processing : 36 / 105\n",
      "0036\n",
      "Processing : 37 / 105\n",
      "0037\n",
      "Processing : 38 / 105\n",
      "0038\n",
      "Processing : 39 / 105\n",
      "0039\n",
      "Processing : 40 / 105\n",
      "0040\n",
      "Processing : 41 / 105\n",
      "0041\n",
      "Processing : 42 / 105\n",
      "0042\n",
      "Processing : 43 / 105\n",
      "0043\n",
      "Processing : 44 / 105\n",
      "0044\n",
      "Processing : 45 / 105\n",
      "0045\n",
      "Processing : 46 / 105\n",
      "0046\n",
      "Processing : 47 / 105\n",
      "0047\n",
      "Processing : 48 / 105\n",
      "0048\n",
      "Processing : 49 / 105\n",
      "0049\n",
      "Processing : 50 / 105\n",
      "0050\n",
      "Processing : 51 / 105\n",
      "0051\n",
      "Processing : 52 / 105\n",
      "0052\n",
      "Processing : 53 / 105\n",
      "0053\n",
      "Processing : 54 / 105\n",
      "0054\n",
      "Processing : 55 / 105\n",
      "0055\n",
      "Processing : 56 / 105\n",
      "0056\n",
      "Processing : 57 / 105\n",
      "0057\n",
      "Processing : 58 / 105\n",
      "0058\n",
      "Processing : 59 / 105\n",
      "0059\n",
      "Processing : 60 / 105\n",
      "0060\n",
      "Processing : 61 / 105\n",
      "0061\n",
      "Processing : 62 / 105\n",
      "0062\n",
      "Processing : 63 / 105\n",
      "0063\n",
      "Processing : 64 / 105\n",
      "0064\n",
      "Processing : 65 / 105\n",
      "0065\n",
      "Processing : 66 / 105\n",
      "0066\n",
      "Processing : 67 / 105\n",
      "0067\n",
      "Processing : 68 / 105\n",
      "0068\n",
      "Processing : 69 / 105\n",
      "0069\n",
      "Processing : 70 / 105\n",
      "0070\n",
      "Processing : 71 / 105\n",
      "0071\n",
      "Processing : 72 / 105\n",
      "0072\n",
      "Processing : 73 / 105\n",
      "0073\n",
      "Processing : 74 / 105\n",
      "0074\n",
      "Processing : 75 / 105\n",
      "0075\n",
      "Processing : 76 / 105\n",
      "0076\n",
      "Processing : 77 / 105\n",
      "0077\n",
      "Processing : 78 / 105\n",
      "0078\n",
      "Processing : 79 / 105\n",
      "0079\n",
      "Processing : 80 / 105\n",
      "0080\n",
      "Processing : 81 / 105\n",
      "0081\n",
      "Processing : 82 / 105\n",
      "0082\n",
      "Processing : 83 / 105\n",
      "0083\n",
      "Processing : 84 / 105\n",
      "0084\n",
      "Processing : 85 / 105\n",
      "0085\n",
      "Processing : 86 / 105\n",
      "0086\n",
      "Processing : 87 / 105\n",
      "0087\n",
      "Processing : 88 / 105\n",
      "0088\n",
      "Processing : 89 / 105\n",
      "0089\n",
      "Processing : 90 / 105\n",
      "0090\n",
      "Processing : 91 / 105\n",
      "0091\n",
      "Processing : 92 / 105\n",
      "0092\n",
      "Processing : 93 / 105\n",
      "0093\n",
      "Processing : 94 / 105\n",
      "0094\n",
      "Processing : 95 / 105\n",
      "0095\n",
      "Processing : 96 / 105\n",
      "0096\n",
      "Processing : 97 / 105\n",
      "0097\n",
      "Processing : 98 / 105\n",
      "0098\n",
      "Processing : 99 / 105\n",
      "0099\n",
      "Processing : 100 / 105\n",
      "0100\n",
      "Processing : 101 / 105\n",
      "0101\n",
      "Processing : 102 / 105\n",
      "0102\n",
      "Processing : 103 / 105\n",
      "0103\n",
      "Processing : 104 / 105\n",
      "0104\n"
     ]
    }
   ],
   "source": [
    "model = init_detector(configs.config_file, configs.weight_file, device=configs.device)\n",
    "confidence_th = 0.9\n",
    "dataset = Dataset(configs.data_dir, configs.result_dir,  fps=configs.fps)\n",
    "\n",
    "total_imgs = len(dataset)\n",
    "detections = {}\n",
    "tags = {}\n",
    "images = {}\n",
    "t2f = []\n",
    "# Inference using the model\n",
    "for idx in range(0, total_imgs):\n",
    "    print(f\"Processing : {idx} / {total_imgs}\")\n",
    "    img_id = f\"{idx:04d}\"\n",
    "    # out_filename = os.path.join(configs.result_dir, f\"{idx}.png\")\n",
    "    img = dataset.get_images(idx)\n",
    "    result = inference_detector(model, img)\n",
    "    class_dets = result[1]\n",
    "    scores = class_dets[:, -1]\n",
    "    class_dets = class_dets[scores>confidence_th,:]\n",
    "    print(img_id)\n",
    "    detections[img_id] = class_dets\n",
    "    tags[img_id] = [a[0:4] for a in class_dets]\n",
    "    images[img_id] = img\n",
    "    t2f.append(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Detection:\n",
    "    center: np.ndarray\n",
    "    minc: np.ndarray\n",
    "    maxc: np.ndarray\n",
    "    area: float\n",
    "    reid: Optional[np.ndarray] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Stats:\n",
    "    minc: np.ndarray\n",
    "    maxc: np.ndarray\n",
    "    num_max_det: int\n",
    "\n",
    "\n",
    "def quiet_divide(a, b):\n",
    "    \"\"\"Quiet divide function that does not warn about (0 / 0).\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "        return np.true_divide(a, b)\n",
    "\n",
    "def calc_HS_histogram(image, roi):\n",
    "    roi = [roi.minc[0], roi.minc[1], roi.maxc[0], roi.maxc[1]]\n",
    "    roi = [int(a) for a in roi]\n",
    "    cropped = image[roi[1]:roi[3], roi[0]:roi[2], :]\n",
    "    hsv = cv2.cvtColor(cropped, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hist = cv2.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "    cv2.normalize(hist, hist, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX).flatten()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def calc_bhattacharyya_distance(hist1, hist2):\n",
    "\treturn cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA)\n",
    "\n",
    "\n",
    "def boxiou(det1, det2):\n",
    "    \"\"\"Computes IOU of two rectangles. Taken from\n",
    "    https://github.com/cheind/py-motmetrics/blob/6597e8a4ed398b9f14880fa76de26bc43d230836/motmetrics/distances.py#L64\n",
    "    \"\"\"\n",
    "    a_min, a_max = det1.minc, det1.maxc\n",
    "    b_min, b_max = det2.minc, det2.maxc\n",
    "    # Compute intersection.\n",
    "    i_min = np.maximum(a_min, b_min)\n",
    "    i_max = np.minimum(a_max, b_max)\n",
    "    i_size = np.maximum(i_max - i_min, 0)\n",
    "    i_vol = np.prod(i_size, axis=-1)\n",
    "    # Get volume of union.\n",
    "    a_size = np.maximum(a_max - a_min, 0)\n",
    "    b_size = np.maximum(b_max - b_min, 0)\n",
    "    a_vol = np.prod(a_size, axis=-1)\n",
    "    b_vol = np.prod(b_size, axis=-1)\n",
    "    u_vol = a_vol + b_vol - i_vol\n",
    "    return np.where(\n",
    "        i_vol == 0, np.zeros_like(i_vol, dtype=float), quiet_divide(i_vol, u_vol)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to solve.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspace/SummerCamp2022/notebooks/offline_tracking/runner.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f77732d7072616779616e2d32227d7d/workspace/SummerCamp2022/notebooks/offline_tracking/runner.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m(iou_logprob)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f77732d7072616779616e2d32227d7d/workspace/SummerCamp2022/notebooks/offline_tracking/runner.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m flowgraph \u001b[39m=\u001b[39m gflow\u001b[39m.\u001b[39mbuild_flow_graph(\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f77732d7072616779616e2d32227d7d/workspace/SummerCamp2022/notebooks/offline_tracking/runner.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m timeseries, GraphCosts(), num_skip_layers\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, cost_scale\u001b[39m=\u001b[39m\u001b[39m1e4\u001b[39m, max_cost\u001b[39m=\u001b[39m\u001b[39m3e3\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f77732d7072616779616e2d32227d7d/workspace/SummerCamp2022/notebooks/offline_tracking/runner.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f77732d7072616779616e2d32227d7d/workspace/SummerCamp2022/notebooks/offline_tracking/runner.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m flowdict, _, _ \u001b[39m=\u001b[39m gflow\u001b[39m.\u001b[39;49msolve(flowgraph, (\u001b[39m1\u001b[39;49m, \u001b[39m20\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f77732d7072616779616e2d32227d7d/workspace/SummerCamp2022/notebooks/offline_tracking/runner.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m traj \u001b[39m=\u001b[39m gflow\u001b[39m.\u001b[39mfind_trajectories(flowdict)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f77732d7072616779616e2d32227d7d/workspace/SummerCamp2022/notebooks/offline_tracking/runner.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m obs_to_traj \u001b[39m=\u001b[39m gflow\u001b[39m.\u001b[39mlabel_observations(timeseries, traj)\n",
      "File \u001b[0;32m/workspace/SummerCamp2022/notebooks/offline_tracking/py-globalflow/globalflow/mot.py:306\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(flowgraph, trajectory_range)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[39mdel\u001b[39;00m e\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m opt[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFailed to solve.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    307\u001b[0m _logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    308\u001b[0m     (\n\u001b[1;32m    309\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFound optimimum in range \u001b[39m\u001b[39m{\u001b[39;00mtrajectory_range\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlog-likelihood \u001b[39m\u001b[39m{\u001b[39;00mopt[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, number of trajectories \u001b[39m\u001b[39m{\u001b[39;00mopt[\u001b[39m2\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m     )\n\u001b[1;32m    312\u001b[0m )\n\u001b[1;32m    313\u001b[0m \u001b[39mreturn\u001b[39;00m opt\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to solve."
     ]
    }
   ],
   "source": [
    "timeseries = []\n",
    "fnames = []\n",
    "\n",
    "\n",
    "stats = Stats(minc=np.array([1e3] * 2), maxc=np.array([-1e3] * 2), num_max_det=0)\n",
    "for t, (fname, objs) in enumerate(detections.items()):\n",
    "    fnames.append(fname)\n",
    "    tdata = []\n",
    "\n",
    "    for oidx, obj in enumerate(objs):\n",
    "        minc = np.array([obj[0], obj[1]])\n",
    "        maxc = np.array([obj[2], obj[3]])\n",
    "        c = (minc + maxc) * 0.5\n",
    "        area = (maxc[0] - minc[0]) * (maxc[1] - minc[1])\n",
    "\n",
    "        tdata.append(Detection(c, minc, maxc, area))\n",
    "        stats.minc = np.minimum(stats.minc, minc)\n",
    "        stats.maxc = np.maximum(stats.maxc, maxc)\n",
    "    timeseries.append(tdata)\n",
    "    stats.num_max_det = max(stats.num_max_det, len(tdata))\n",
    "\n",
    "class GraphCosts(gflow.StandardGraphCosts):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            penter=1e-2,\n",
    "            pexit=1e-4,\n",
    "            beta=2e-2,\n",
    "            max_obs_time=len(timeseries) - 1,\n",
    "        )\n",
    "\n",
    "    def transition_cost(self, x: gflow.FlowNode, y: gflow.FlowNode) -> float:\n",
    "        \"\"\"Log-probability of pairing xi(t-1) with xj(t).\n",
    "        Modelled by intersection over union downweighted by an\n",
    "        exponential decreasing probability on the time-difference.\n",
    "        \"\"\"\n",
    "        iou_logprob = np.log(boxiou(x.obs, y.obs) + 1e-8)\n",
    "        tdiff = y.time_index - x.time_index\n",
    "        tlogprob = scipy.stats.expon.logpdf(\n",
    "            tdiff, loc=1.0, scale=1 / 1.0\n",
    "        )\n",
    "        hist1 = calc_HS_histogram(images[t2f[x.time_index]], x.obs)\n",
    "        hist2 = calc_HS_histogram(images[t2f[y.time_index]], x.obs)\n",
    "        prob_color = 1.0 - calc_bhattacharyya_distance(hist1, hist2)\n",
    "        return -(iou_logprob)\n",
    "\n",
    "flowgraph = gflow.build_flow_graph(\n",
    "timeseries, GraphCosts(), num_skip_layers=3, cost_scale=1e4, max_cost=3e3\n",
    ")\n",
    "flowdict, _, _ = gflow.solve(flowgraph, (1, 20))\n",
    "traj = gflow.find_trajectories(flowdict)\n",
    "obs_to_traj = gflow.label_observations(timeseries, traj)\n",
    "traj_info = [\n",
    "    {\"idx\": tidx, \"start\": fnames[t[0].time_index], \"end\": fnames[t[-1].time_index]}\n",
    "    for tidx, t in enumerate(traj)\n",
    "]\n",
    "# Use filenames instead of time indices\n",
    "obs_to_traj = {fname: ids for fname, ids in zip(fnames, obs_to_traj)}\n",
    "print(obs_to_traj, traj_info, stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.visulaizations import draw_bb\n",
    "\n",
    "\n",
    "palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
    "def compute_color_for_labels(label):\n",
    "    \"\"\"\n",
    "    Simple function that adds fixed color depending on the class\n",
    "    \"\"\"\n",
    "    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
    "    return tuple(color)\n",
    "def draw_boxes(img, bbox, identities=None, offset=(0,0)):\n",
    "    for i,box in enumerate(bbox):\n",
    "        x1,y1,x2,y2 = [int(i) for i in box]\n",
    "        x1 += offset[0]\n",
    "        x2 += offset[0]\n",
    "        y1 += offset[1]\n",
    "        y2 += offset[1]\n",
    "        # box text and bar\n",
    "        id = int(identities[i]) if identities is not None else 0    \n",
    "        color = compute_color_for_labels(id)\n",
    "        label = '{}{:d}'.format(\"\", id)\n",
    "        t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 2 , 2)[0]\n",
    "        cv2.rectangle(img,(x1, y1),(x2,y2),color,3)\n",
    "        cv2.rectangle(img,(x1, y1),(x1+t_size[0]+3,y1+t_size[1]+4), color,-1)\n",
    "        cv2.putText(img,label,(x1,y1+t_size[1]+4), cv2.FONT_HERSHEY_PLAIN, 2, [255,255,255], 2)\n",
    "    return img\n",
    "\n",
    "RESULT_DIR = \"../../results/mcftracker\"\n",
    "\n",
    "# 書き込み設定\n",
    "fourcc = cv2.VideoWriter_fourcc('m','p','4', 'v')\n",
    "im_width = img.shape[1]\n",
    "im_height = img.shape[0]\n",
    "fps = 15\n",
    "\n",
    "save_video_path = f\"{RESULT_DIR}/results.mp4\"\n",
    "\n",
    "video = cv2.VideoWriter(filename=save_video_path,\n",
    "                        fourcc=fourcc,\n",
    "                        fps=fps,\n",
    "                        frameSize=(int(im_width),int(im_height)))\n",
    "\n",
    "for fname in images.keys():\n",
    "    ids = obs_to_traj[fname]\n",
    "    bbs = detections[fname]\n",
    "\n",
    "    img = images[fname]\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    overlayed = draw_boxes(img, [[bb[0], bb[1], bb[2], bb[3]] for bb in bbs], ids)\n",
    "    video.write(overlayed)\n",
    "video.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
