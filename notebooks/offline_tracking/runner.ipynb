{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Data paths\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Path追加\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import configargparse\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from args import get_config\n",
    "from data import Dataset\n",
    "from common.visulaizations import draw_bb\n",
    "\n",
    "import time\n",
    "import globalflow as gflow\n",
    "\n",
    "configs = get_config(\"-c ../../configs/mcftracker.ini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../../weights/old.pth\n",
      "Processing : 0 / 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/mmdet/datasets/utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000\n",
      "Processing : 1 / 105\n",
      "0001\n",
      "Processing : 2 / 105\n",
      "0002\n",
      "Processing : 3 / 105\n",
      "0003\n",
      "Processing : 4 / 105\n",
      "0004\n",
      "Processing : 5 / 105\n",
      "0005\n",
      "Processing : 6 / 105\n",
      "0006\n",
      "Processing : 7 / 105\n",
      "0007\n",
      "Processing : 8 / 105\n",
      "0008\n",
      "Processing : 9 / 105\n",
      "0009\n",
      "Processing : 10 / 105\n",
      "0010\n",
      "Processing : 11 / 105\n",
      "0011\n",
      "Processing : 12 / 105\n",
      "0012\n",
      "Processing : 13 / 105\n",
      "0013\n",
      "Processing : 14 / 105\n",
      "0014\n",
      "Processing : 15 / 105\n",
      "0015\n",
      "Processing : 16 / 105\n",
      "0016\n",
      "Processing : 17 / 105\n",
      "0017\n",
      "Processing : 18 / 105\n",
      "0018\n",
      "Processing : 19 / 105\n",
      "0019\n",
      "Processing : 20 / 105\n",
      "0020\n",
      "Processing : 21 / 105\n",
      "0021\n",
      "Processing : 22 / 105\n",
      "0022\n",
      "Processing : 23 / 105\n",
      "0023\n",
      "Processing : 24 / 105\n",
      "0024\n",
      "Processing : 25 / 105\n",
      "0025\n",
      "Processing : 26 / 105\n",
      "0026\n",
      "Processing : 27 / 105\n",
      "0027\n",
      "Processing : 28 / 105\n",
      "0028\n",
      "Processing : 29 / 105\n",
      "0029\n",
      "Processing : 30 / 105\n",
      "0030\n",
      "Processing : 31 / 105\n",
      "0031\n",
      "Processing : 32 / 105\n",
      "0032\n",
      "Processing : 33 / 105\n",
      "0033\n",
      "Processing : 34 / 105\n",
      "0034\n",
      "Processing : 35 / 105\n",
      "0035\n",
      "Processing : 36 / 105\n",
      "0036\n",
      "Processing : 37 / 105\n",
      "0037\n",
      "Processing : 38 / 105\n",
      "0038\n",
      "Processing : 39 / 105\n",
      "0039\n",
      "Processing : 40 / 105\n",
      "0040\n",
      "Processing : 41 / 105\n",
      "0041\n",
      "Processing : 42 / 105\n",
      "0042\n",
      "Processing : 43 / 105\n",
      "0043\n",
      "Processing : 44 / 105\n",
      "0044\n",
      "Processing : 45 / 105\n",
      "0045\n",
      "Processing : 46 / 105\n",
      "0046\n",
      "Processing : 47 / 105\n",
      "0047\n",
      "Processing : 48 / 105\n",
      "0048\n",
      "Processing : 49 / 105\n",
      "0049\n",
      "Processing : 50 / 105\n",
      "0050\n",
      "Processing : 51 / 105\n",
      "0051\n",
      "Processing : 52 / 105\n",
      "0052\n",
      "Processing : 53 / 105\n",
      "0053\n",
      "Processing : 54 / 105\n",
      "0054\n",
      "Processing : 55 / 105\n",
      "0055\n",
      "Processing : 56 / 105\n",
      "0056\n",
      "Processing : 57 / 105\n",
      "0057\n",
      "Processing : 58 / 105\n",
      "0058\n",
      "Processing : 59 / 105\n",
      "0059\n",
      "Processing : 60 / 105\n",
      "0060\n",
      "Processing : 61 / 105\n",
      "0061\n",
      "Processing : 62 / 105\n",
      "0062\n",
      "Processing : 63 / 105\n",
      "0063\n",
      "Processing : 64 / 105\n",
      "0064\n",
      "Processing : 65 / 105\n",
      "0065\n",
      "Processing : 66 / 105\n",
      "0066\n",
      "Processing : 67 / 105\n",
      "0067\n",
      "Processing : 68 / 105\n",
      "0068\n",
      "Processing : 69 / 105\n",
      "0069\n",
      "Processing : 70 / 105\n",
      "0070\n",
      "Processing : 71 / 105\n",
      "0071\n",
      "Processing : 72 / 105\n",
      "0072\n",
      "Processing : 73 / 105\n",
      "0073\n",
      "Processing : 74 / 105\n",
      "0074\n",
      "Processing : 75 / 105\n",
      "0075\n",
      "Processing : 76 / 105\n",
      "0076\n",
      "Processing : 77 / 105\n",
      "0077\n",
      "Processing : 78 / 105\n",
      "0078\n",
      "Processing : 79 / 105\n",
      "0079\n",
      "Processing : 80 / 105\n",
      "0080\n",
      "Processing : 81 / 105\n",
      "0081\n",
      "Processing : 82 / 105\n",
      "0082\n",
      "Processing : 83 / 105\n",
      "0083\n",
      "Processing : 84 / 105\n",
      "0084\n",
      "Processing : 85 / 105\n",
      "0085\n",
      "Processing : 86 / 105\n",
      "0086\n",
      "Processing : 87 / 105\n",
      "0087\n",
      "Processing : 88 / 105\n",
      "0088\n",
      "Processing : 89 / 105\n",
      "0089\n",
      "Processing : 90 / 105\n",
      "0090\n",
      "Processing : 91 / 105\n",
      "0091\n",
      "Processing : 92 / 105\n",
      "0092\n",
      "Processing : 93 / 105\n",
      "0093\n",
      "Processing : 94 / 105\n",
      "0094\n",
      "Processing : 95 / 105\n",
      "0095\n",
      "Processing : 96 / 105\n",
      "0096\n",
      "Processing : 97 / 105\n",
      "0097\n",
      "Processing : 98 / 105\n",
      "0098\n",
      "Processing : 99 / 105\n",
      "0099\n",
      "Processing : 100 / 105\n",
      "0100\n",
      "Processing : 101 / 105\n",
      "0101\n",
      "Processing : 102 / 105\n",
      "0102\n",
      "Processing : 103 / 105\n",
      "0103\n",
      "Processing : 104 / 105\n",
      "0104\n"
     ]
    }
   ],
   "source": [
    "model = init_detector(configs.config_file, configs.weight_file, device=configs.device)\n",
    "confidence_th = 0.9\n",
    "dataset = Dataset(configs.data_dir, configs.result_dir,  fps=configs.fps)\n",
    "\n",
    "total_imgs = len(dataset)\n",
    "detections = {}\n",
    "tags = {}\n",
    "images = {}\n",
    "t2f = []\n",
    "# Inference using the model\n",
    "for idx in range(0, total_imgs):\n",
    "    print(f\"Processing : {idx} / {total_imgs}\")\n",
    "    img_id = f\"{idx:04d}\"\n",
    "    # out_filename = os.path.join(configs.result_dir, f\"{idx}.png\")\n",
    "    img = dataset.get_images(idx)\n",
    "    result = inference_detector(model, img)\n",
    "    class_dets = result[0]\n",
    "    scores = class_dets[:, -1]\n",
    "    class_dets = class_dets[scores>confidence_th,:]\n",
    "    print(img_id)\n",
    "    detections[img_id] = class_dets\n",
    "    tags[img_id] = [a[0:4] for a in class_dets]\n",
    "    images[img_id] = img\n",
    "    t2f.append(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Detection:\n",
    "    center: np.ndarray\n",
    "    minc: np.ndarray\n",
    "    maxc: np.ndarray\n",
    "    area: float\n",
    "    reid: Optional[np.ndarray] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Stats:\n",
    "    minc: np.ndarray\n",
    "    maxc: np.ndarray\n",
    "    num_max_det: int\n",
    "\n",
    "\n",
    "def quiet_divide(a, b):\n",
    "    \"\"\"Quiet divide function that does not warn about (0 / 0).\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "        return np.true_divide(a, b)\n",
    "\n",
    "def calc_HS_histogram(image, roi):\n",
    "    roi = [roi.minc[0], roi.minc[1], roi.maxc[0], roi.maxc[1]]\n",
    "    roi = [int(a) for a in roi]\n",
    "    cropped = image[roi[1]:roi[3], roi[0]:roi[2], :]\n",
    "    hsv = cv2.cvtColor(cropped, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hist = cv2.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "    cv2.normalize(hist, hist, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX).flatten()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def calc_bhattacharyya_distance(hist1, hist2):\n",
    "\treturn cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA)\n",
    "\n",
    "\n",
    "def boxiou(det1, det2):\n",
    "    \"\"\"Computes IOU of two rectangles. Taken from\n",
    "    https://github.com/cheind/py-motmetrics/blob/6597e8a4ed398b9f14880fa76de26bc43d230836/motmetrics/distances.py#L64\n",
    "    \"\"\"\n",
    "    a_min, a_max = det1.minc, det1.maxc\n",
    "    b_min, b_max = det2.minc, det2.maxc\n",
    "    # Compute intersection.\n",
    "    i_min = np.maximum(a_min, b_min)\n",
    "    i_max = np.minimum(a_max, b_max)\n",
    "    i_size = np.maximum(i_max - i_min, 0)\n",
    "    i_vol = np.prod(i_size, axis=-1)\n",
    "    # Get volume of union.\n",
    "    a_size = np.maximum(a_max - a_min, 0)\n",
    "    b_size = np.maximum(b_max - b_min, 0)\n",
    "    a_vol = np.prod(a_size, axis=-1)\n",
    "    b_vol = np.prod(b_size, axis=-1)\n",
    "    u_vol = a_vol + b_vol - i_vol\n",
    "    return np.where(\n",
    "        i_vol == 0, np.zeros_like(i_vol, dtype=float), quiet_divide(i_vol, u_vol)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter\n",
      "{'0000': [-1, 0, 1, 2, 3], '0001': [0, 1, 3, 2, -1], '0002': [0, 1, 3, 2], '0003': [1, 0, 3, 2], '0004': [1, 0, 3, 2], '0005': [1, 0, 2, 3, -1], '0006': [1, 0, 2, 3], '0007': [1, 0, 2], '0008': [1, 3, 2], '0009': [1, 0, 2, -1], '0010': [0, 1], '0011': [0, 1, 4, 2], '0012': [0, 3, 1, 4, 2], '0013': [4, 0, 2, 1, 3], '0014': [2, 3, 4, 1], '0015': [2, 0, 3, -1, 1], '0016': [2, 0, 3, 1, -1], '0017': [2, 0, 3], '0018': [0, 4, 3, 2, 5], '0019': [4, 0, 5, 3], '0020': [5, 0, 4, 3, 2], '0021': [5, 0, 2, 3, 4], '0022': [5, 0, 3, 2], '0023': [5, 2, 3, 4], '0024': [5, 0, 2, 3], '0025': [5, 4, 3, 2], '0026': [5, 4, 3, 2, -1], '0027': [5, 4, 3, 2, -1], '0028': [0, 5, 3, 2, -1], '0029': [5, 4, -1, 3, 2], '0030': [5, 4, 3, 2], '0031': [5, 0, 3, -1, 2], '0032': [5, 0, 2, 3], '0033': [5, 0, 3, 2], '0034': [5, 4, 3, 2], '0035': [5, 4, 3, 6, 2], '0036': [5, 4, 3, 6], '0037': [5, 0, 3, 2, 6], '0038': [4, 5, 3, 2, 6], '0039': [4, 5, 3, 6, 2], '0040': [4, 5, 3, -1, 2, 0, -1], '0041': [4, 5, 3, -1, 2], '0042': [5, 4, 3, 6, -1, 2, 0], '0043': [5, 4, 3, 2, 6], '0044': [5, 4, 3, 2], '0045': [5, 4, 3, 0, 2], '0046': [4, 5, 3, 0], '0047': [4, 5, 3, 6], '0048': [5, 4, 0, 3, 6], '0049': [3, 6, 0, 4, 5], '0050': [3, 4, 6, 0], '0051': [3, 4, 6, 0], '0052': [3, 4, 6], '0053': [3, 5, 0], '0054': [3, 4, 0], '0055': [3, 5, 0], '0056': [3, 6, 4], '0057': [3, 6, 5, 4, 7], '0058': [3, 4, 5, 7, 0], '0059': [3, 4, 5, 7, 0], '0060': [4, 3, 5, 7], '0061': [4, 3, 5, 6, 7], '0062': [5, 3, 4, 7, 8], '0063': [4, 3, 5, 0, 7], '0064': [4, 5, 3, 0, 6, 8, 7], '0065': [4, 0, 3, 8, 5, 7], '0066': [4, 0, 7, 8, 5, 3], '0067': [4, 0, 3, 7, 8], '0068': [4, 0, 5, 7, 8], '0069': [4, 0, 5, 7], '0070': [4, 0, 5, 7], '0071': [4, 0, 3, 7, 8], '0072': [4, 0, 5, 7, 8], '0073': [4, 0, 5, 7, 8], '0074': [4, 0, 5, 7, 8], '0075': [0, 4, 5, 3, 7], '0076': [4, 0, 3, 5, 7], '0077': [4, 5, 0, 7, 3], '0078': [4, 5, 3, 7, 9], '0079': [4, 5, -1, 0, 7], '0080': [4, 5, 3, 9, 7], '0081': [4, 5, 7, 0], '0082': [4, 7, 9, 0, -1], '0083': [4, 7, 3, -1], '0084': [4, 0, 7, -1], '0085': [0, 4, 7, 3], '0086': [0, 9, 7, 3], '0087': [0, 4, 7], '0088': [0, 7, 3, 4], '0089': [0, 7, 3, 4], '0090': [0, 9, 3, 7], '0091': [0, 3, 9, 7], '0092': [0, 4, 3, 7], '0093': [0, 9, 7, 3], '0094': [9, 0, 7], '0095': [0, 9, 4, 7, 3], '0096': [0, 9, 4, 7, -1], '0097': [0, 9, 4, 3], '0098': [0, 9, 7, 4], '0099': [0, 9, 7], '0100': [9, 0, 7], '0101': [9, 3, 7, 4], '0102': [9, 3, 7], '0103': [9, 3, 10, 7, 4], '0104': [9, 4, 7, 3, 10]} [{'idx': 0, 'start': '0000', 'end': '0100'}, {'idx': 1, 'start': '0000', 'end': '0016'}, {'idx': 2, 'start': '0000', 'end': '0045'}, {'idx': 3, 'start': '0000', 'end': '0104'}, {'idx': 4, 'start': '0011', 'end': '0104'}, {'idx': 5, 'start': '0018', 'end': '0081'}, {'idx': 6, 'start': '0035', 'end': '0064'}, {'idx': 7, 'start': '0057', 'end': '0104'}, {'idx': 8, 'start': '0062', 'end': '0074'}, {'idx': 9, 'start': '0078', 'end': '0104'}, {'idx': 10, 'start': '0103', 'end': '0104'}] Stats(minc=array([322.04833984,   0.        ]), maxc=array([1477.3470459 , 1001.87756348]), num_max_det=7)\n"
     ]
    }
   ],
   "source": [
    "timeseries = []\n",
    "fnames = []\n",
    "\n",
    "\n",
    "stats = Stats(minc=np.array([1e3] * 2), maxc=np.array([-1e3] * 2), num_max_det=0)\n",
    "for t, (fname, objs) in enumerate(detections.items()):\n",
    "    fnames.append(fname)\n",
    "    tdata = []\n",
    "\n",
    "    for oidx, obj in enumerate(objs):\n",
    "        minc = np.array([obj[0], obj[1]])\n",
    "        maxc = np.array([obj[2], obj[3]])\n",
    "        c = (minc + maxc) * 0.5\n",
    "        area = (maxc[0] - minc[0]) * (maxc[1] - minc[1])\n",
    "\n",
    "        tdata.append(Detection(c, minc, maxc, area))\n",
    "        stats.minc = np.minimum(stats.minc, minc)\n",
    "        stats.maxc = np.maximum(stats.maxc, maxc)\n",
    "    timeseries.append(tdata)\n",
    "    stats.num_max_det = max(stats.num_max_det, len(tdata))\n",
    "\n",
    "class GraphCosts(gflow.StandardGraphCosts):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            penter=1e-2,\n",
    "            pexit=1e-4,\n",
    "            beta=2e-2,\n",
    "            max_obs_time=len(timeseries) - 1,\n",
    "        )\n",
    "        print(\"enter\")\n",
    "\n",
    "    def transition_cost(self, x: gflow.FlowNode, y: gflow.FlowNode) -> float:\n",
    "        \"\"\"Log-probability of pairing xi(t-1) with xj(t).\n",
    "        Modelled by intersection over union downweighted by an\n",
    "        exponential decreasing probability on the time-difference.\n",
    "        \"\"\"\n",
    "        iou_logprob = np.log(boxiou(x.obs, y.obs) + 1e-8)\n",
    "        tdiff = y.time_index - x.time_index\n",
    "        tlogprob = scipy.stats.expon.logpdf(\n",
    "            tdiff, loc=1.0, scale=1 / 1.0\n",
    "        )\n",
    "        hist1 = calc_HS_histogram(images[t2f[x.time_index]], x.obs)\n",
    "        hist2 = calc_HS_histogram(images[t2f[y.time_index]], x.obs)\n",
    "        prob_color = 1.0 - calc_bhattacharyya_distance(hist1, hist2)\n",
    "        return -(iou_logprob)\n",
    "\n",
    "flowgraph = gflow.build_flow_graph(\n",
    "timeseries, GraphCosts(), num_skip_layers=3, cost_scale=1e4, max_cost=3e3\n",
    ")\n",
    "flowdict, _, _ = gflow.solve(flowgraph, (1, 20))\n",
    "traj = gflow.find_trajectories(flowdict)\n",
    "obs_to_traj = gflow.label_observations(timeseries, traj)\n",
    "traj_info = [\n",
    "    {\"idx\": tidx, \"start\": fnames[t[0].time_index], \"end\": fnames[t[-1].time_index]}\n",
    "    for tidx, t in enumerate(traj)\n",
    "]\n",
    "# Use filenames instead of time indices\n",
    "obs_to_traj = {fname: ids for fname, ids in zip(fnames, obs_to_traj)}\n",
    "print(obs_to_traj, traj_info, stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.visulaizations import draw_bb\n",
    "\n",
    "\n",
    "palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
    "def compute_color_for_labels(label):\n",
    "    \"\"\"\n",
    "    Simple function that adds fixed color depending on the class\n",
    "    \"\"\"\n",
    "    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
    "    return tuple(color)\n",
    "def draw_boxes(img, bbox, identities=None, offset=(0,0)):\n",
    "    for i,box in enumerate(bbox):\n",
    "        x1,y1,x2,y2 = [int(i) for i in box]\n",
    "        x1 += offset[0]\n",
    "        x2 += offset[0]\n",
    "        y1 += offset[1]\n",
    "        y2 += offset[1]\n",
    "        # box text and bar\n",
    "        id = int(identities[i]) if identities is not None else 0    \n",
    "        color = compute_color_for_labels(id)\n",
    "        label = '{}{:d}'.format(\"\", id)\n",
    "        t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 2 , 2)[0]\n",
    "        cv2.rectangle(img,(x1, y1),(x2,y2),color,3)\n",
    "        cv2.rectangle(img,(x1, y1),(x1+t_size[0]+3,y1+t_size[1]+4), color,-1)\n",
    "        cv2.putText(img,label,(x1,y1+t_size[1]+4), cv2.FONT_HERSHEY_PLAIN, 2, [255,255,255], 2)\n",
    "    return img\n",
    "\n",
    "RESULT_DIR = \"../../results/mcftracker\"\n",
    "\n",
    "# 書き込み設定\n",
    "fourcc = cv2.VideoWriter_fourcc('m','p','4', 'v')\n",
    "im_width = img.shape[1]\n",
    "im_height = img.shape[0]\n",
    "fps = 15\n",
    "\n",
    "save_video_path = f\"{RESULT_DIR}/results.mp4\"\n",
    "\n",
    "video = cv2.VideoWriter(filename=save_video_path,\n",
    "                        fourcc=fourcc,\n",
    "                        fps=fps,\n",
    "                        frameSize=(int(im_width),int(im_height)))\n",
    "\n",
    "for fname in images.keys():\n",
    "    ids = obs_to_traj[fname]\n",
    "    bbs = detections[fname]\n",
    "\n",
    "    img = images[fname]\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    overlayed = draw_boxes(img, [[bb[0], bb[1], bb[2], bb[3]] for bb in bbs], ids)\n",
    "    video.write(overlayed)\n",
    "video.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
