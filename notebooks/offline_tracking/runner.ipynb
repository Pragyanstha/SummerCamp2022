{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Data paths\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Path追加\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import configargparse\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from args import get_config\n",
    "from data import Dataset\n",
    "from common.visulaizations import draw_bb\n",
    "\n",
    "import time\n",
    "import globalflow as gflow\n",
    "\n",
    "configs = get_config(\"-c ../../configs/mcftracker.ini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../../weights/old.pth\n",
      "Processing : 0 / 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/mmdet/datasets/utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000\n",
      "Processing : 1 / 21\n",
      "0001\n",
      "Processing : 2 / 21\n",
      "0002\n",
      "Processing : 3 / 21\n",
      "0003\n",
      "Processing : 4 / 21\n",
      "0004\n",
      "Processing : 5 / 21\n",
      "0005\n",
      "Processing : 6 / 21\n",
      "0006\n",
      "Processing : 7 / 21\n",
      "0007\n",
      "Processing : 8 / 21\n",
      "0008\n",
      "Processing : 9 / 21\n",
      "0009\n",
      "Processing : 10 / 21\n",
      "0010\n",
      "Processing : 11 / 21\n",
      "0011\n",
      "Processing : 12 / 21\n",
      "0012\n",
      "Processing : 13 / 21\n",
      "0013\n",
      "Processing : 14 / 21\n",
      "0014\n",
      "Processing : 15 / 21\n",
      "0015\n",
      "Processing : 16 / 21\n",
      "0016\n",
      "Processing : 17 / 21\n",
      "0017\n",
      "Processing : 18 / 21\n",
      "0018\n",
      "Processing : 19 / 21\n",
      "0019\n",
      "Processing : 20 / 21\n",
      "0020\n"
     ]
    }
   ],
   "source": [
    "model = init_detector(configs.config_file, configs.weight_file, device=configs.device)\n",
    "confidence_th = 0.9\n",
    "dataset = Dataset(configs.data_dir, configs.result_dir,  fps=configs.fps)\n",
    "\n",
    "total_imgs = len(dataset)\n",
    "detections = {}\n",
    "tags = {}\n",
    "images = {}\n",
    "t2f = []\n",
    "# Inference using the model\n",
    "for idx in range(0, total_imgs):\n",
    "    print(f\"Processing : {idx} / {total_imgs}\")\n",
    "    img_id = f\"{idx:04d}\"\n",
    "    # out_filename = os.path.join(configs.result_dir, f\"{idx}.png\")\n",
    "    img = dataset.get_images(idx)\n",
    "    result = inference_detector(model, img)\n",
    "    class_dets = result[0]\n",
    "    scores = class_dets[:, -1]\n",
    "    class_dets = class_dets[scores>confidence_th,:]\n",
    "    print(img_id)\n",
    "    detections[img_id] = class_dets\n",
    "    tags[img_id] = [a[0:4] for a in class_dets]\n",
    "    images[img_id] = img\n",
    "    t2f.append(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Detection:\n",
    "    center: np.ndarray\n",
    "    minc: np.ndarray\n",
    "    maxc: np.ndarray\n",
    "    area: float\n",
    "    reid: Optional[np.ndarray] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Stats:\n",
    "    minc: np.ndarray\n",
    "    maxc: np.ndarray\n",
    "    num_max_det: int\n",
    "\n",
    "\n",
    "def quiet_divide(a, b):\n",
    "    \"\"\"Quiet divide function that does not warn about (0 / 0).\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "        return np.true_divide(a, b)\n",
    "\n",
    "def calc_HS_histogram(image, roi):\n",
    "    roi = [roi.minc[0], roi.minc[1], roi.maxc[0], roi.maxc[1]]\n",
    "    roi = [int(a) for a in roi]\n",
    "    cropped = image[roi[1]:roi[3], roi[0]:roi[2], :]\n",
    "    hsv = cv2.cvtColor(cropped, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hist = cv2.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "    cv2.normalize(hist, hist, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX).flatten()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def calc_bhattacharyya_distance(hist1, hist2):\n",
    "\treturn cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA)\n",
    "\n",
    "\n",
    "def boxiou(det1, det2):\n",
    "    \"\"\"Computes IOU of two rectangles. Taken from\n",
    "    https://github.com/cheind/py-motmetrics/blob/6597e8a4ed398b9f14880fa76de26bc43d230836/motmetrics/distances.py#L64\n",
    "    \"\"\"\n",
    "    a_min, a_max = det1.minc, det1.maxc\n",
    "    b_min, b_max = det2.minc, det2.maxc\n",
    "    # Compute intersection.\n",
    "    i_min = np.maximum(a_min, b_min)\n",
    "    i_max = np.minimum(a_max, b_max)\n",
    "    i_size = np.maximum(i_max - i_min, 0)\n",
    "    i_vol = np.prod(i_size, axis=-1)\n",
    "    # Get volume of union.\n",
    "    a_size = np.maximum(a_max - a_min, 0)\n",
    "    b_size = np.maximum(b_max - b_min, 0)\n",
    "    a_vol = np.prod(a_size, axis=-1)\n",
    "    b_vol = np.prod(b_size, axis=-1)\n",
    "    u_vol = a_vol + b_vol - i_vol\n",
    "    return np.where(\n",
    "        i_vol == 0, np.zeros_like(i_vol, dtype=float), quiet_divide(i_vol, u_vol)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter\n",
      "{'0000': [0, 1, 2, 3], '0001': [0, 1, 3, -1], '0002': [3, 2, 1, 0], '0003': [-1, 1, -1, 2], '0004': [-1, 1, 3, 2], '0005': [4, 1, -1, 2, 3], '0006': [4, 1, 2, 3], '0007': [1, 4, 2, -1, 3], '0008': [4, 1, 2, 3], '0009': [2, 5, -1, 1, 4], '0010': [2, 1, 5], '0011': [2, 4, 1, 3, 5], '0012': [4, 1, 2, 5, -1, -1, 3], '0013': [4, 5, 2, 3], '0014': [4, 5, 1, 3, -1], '0015': [4, 1, -1, 5, 3], '0016': [4, 5, 3, -1], '0017': [2, 3, 5, 4], '0018': [4, 2, 3], '0019': [2, 4, 3], '0020': [4, -1, 3, 2, -1]} [{'idx': 0, 'start': '0000', 'end': '0002'}, {'idx': 1, 'start': '0000', 'end': '0015'}, {'idx': 2, 'start': '0000', 'end': '0020'}, {'idx': 3, 'start': '0000', 'end': '0020'}, {'idx': 4, 'start': '0005', 'end': '0020'}, {'idx': 5, 'start': '0009', 'end': '0017'}] Stats(minc=array([342.36358643,   0.        ]), maxc=array([1475.38562012, 1001.87695312]), num_max_det=7)\n"
     ]
    }
   ],
   "source": [
    "timeseries = []\n",
    "fnames = []\n",
    "\n",
    "\n",
    "stats = Stats(minc=np.array([1e3] * 2), maxc=np.array([-1e3] * 2), num_max_det=0)\n",
    "for t, (fname, objs) in enumerate(detections.items()):\n",
    "    fnames.append(fname)\n",
    "    tdata = []\n",
    "\n",
    "    for oidx, obj in enumerate(objs):\n",
    "        minc = np.array([obj[0], obj[1]])\n",
    "        maxc = np.array([obj[2], obj[3]])\n",
    "        c = (minc + maxc) * 0.5\n",
    "        area = (maxc[0] - minc[0]) * (maxc[1] - minc[1])\n",
    "\n",
    "        tdata.append(Detection(c, minc, maxc, area))\n",
    "        stats.minc = np.minimum(stats.minc, minc)\n",
    "        stats.maxc = np.maximum(stats.maxc, maxc)\n",
    "    timeseries.append(tdata)\n",
    "    stats.num_max_det = max(stats.num_max_det, len(tdata))\n",
    "\n",
    "class GraphCosts(gflow.StandardGraphCosts):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            penter=1e-2,\n",
    "            pexit=1e-4,\n",
    "            beta=2e-2,\n",
    "            max_obs_time=len(timeseries) - 1,\n",
    "        )\n",
    "        print(\"enter\")\n",
    "\n",
    "    def transition_cost(self, x: gflow.FlowNode, y: gflow.FlowNode) -> float:\n",
    "        \"\"\"Log-probability of pairing xi(t-1) with xj(t).\n",
    "        Modelled by intersection over union downweighted by an\n",
    "        exponential decreasing probability on the time-difference.\n",
    "        \"\"\"\n",
    "        iou_logprob = np.log(boxiou(x.obs, y.obs) + 1e-8)\n",
    "        tdiff = y.time_index - x.time_index\n",
    "        tlogprob = scipy.stats.expon.logpdf(\n",
    "            tdiff, loc=1.0, scale=1 / 1.0\n",
    "        )\n",
    "        hist1 = calc_HS_histogram(images[t2f[x.time_index]], x.obs)\n",
    "        hist2 = calc_HS_histogram(images[t2f[y.time_index]], x.obs)\n",
    "        prob_color = 1.0 - calc_bhattacharyya_distance(hist1, hist2)\n",
    "        return -(iou_logprob)\n",
    "\n",
    "flowgraph = gflow.build_flow_graph(\n",
    "timeseries, GraphCosts(), num_skip_layers=3, cost_scale=1e4, max_cost=3e3\n",
    ")\n",
    "flowdict, _, _ = gflow.solve(flowgraph, (1, 20))\n",
    "traj = gflow.find_trajectories(flowdict)\n",
    "obs_to_traj = gflow.label_observations(timeseries, traj)\n",
    "traj_info = [\n",
    "    {\"idx\": tidx, \"start\": fnames[t[0].time_index], \"end\": fnames[t[-1].time_index]}\n",
    "    for tidx, t in enumerate(traj)\n",
    "]\n",
    "# Use filenames instead of time indices\n",
    "obs_to_traj = {fname: ids for fname, ids in zip(fnames, obs_to_traj)}\n",
    "print(obs_to_traj, traj_info, stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.visulaizations import draw_bb\n",
    "\n",
    "\n",
    "palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
    "def compute_color_for_labels(label):\n",
    "    \"\"\"\n",
    "    Simple function that adds fixed color depending on the class\n",
    "    \"\"\"\n",
    "    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
    "    return tuple(color)\n",
    "def draw_boxes(img, bbox, identities=None, offset=(0,0)):\n",
    "    for i,box in enumerate(bbox):\n",
    "        x1,y1,x2,y2 = [int(i) for i in box]\n",
    "        x1 += offset[0]\n",
    "        x2 += offset[0]\n",
    "        y1 += offset[1]\n",
    "        y2 += offset[1]\n",
    "        # box text and bar\n",
    "        id = int(identities[i]) if identities is not None else 0    \n",
    "        color = compute_color_for_labels(id)\n",
    "        label = '{}{:d}'.format(\"\", id)\n",
    "        t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 2 , 2)[0]\n",
    "        cv2.rectangle(img,(x1, y1),(x2,y2),color,3)\n",
    "        cv2.rectangle(img,(x1, y1),(x1+t_size[0]+3,y1+t_size[1]+4), color,-1)\n",
    "        cv2.putText(img,label,(x1,y1+t_size[1]+4), cv2.FONT_HERSHEY_PLAIN, 2, [255,255,255], 2)\n",
    "    return img\n",
    "\n",
    "RESULT_DIR = \"../../results/mcftracker\"\n",
    "\n",
    "# 書き込み設定\n",
    "fourcc = cv2.VideoWriter_fourcc('m','p','4', 'v')\n",
    "im_width = img.shape[1]\n",
    "im_height = img.shape[0]\n",
    "fps = 15\n",
    "\n",
    "save_video_path = f\"{RESULT_DIR}/results.mp4\"\n",
    "\n",
    "video = cv2.VideoWriter(filename=save_video_path,\n",
    "                        fourcc=fourcc,\n",
    "                        fps=fps,\n",
    "                        frameSize=(int(im_width),int(im_height)))\n",
    "\n",
    "for fname in images.keys():\n",
    "    ids = obs_to_traj[fname]\n",
    "    bbs = detections[fname]\n",
    "\n",
    "    img = images[fname]\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    overlayed = draw_boxes(img, [[bb[0], bb[1], bb[2], bb[3]] for bb in bbs], ids)\n",
    "    video.write(overlayed)\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
