{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Data paths\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Path追加\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import configargparse\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from args import get_config\n",
    "from data import Dataset\n",
    "from common.visulaizations import draw_bb\n",
    "\n",
    "import time\n",
    "import globalflow as gflow\n",
    "\n",
    "configs = get_config(\"-c ../../configs/mcftracker_notebook.ini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../../weights/latest.pth\n",
      "Processing : 0 / 90\n",
      "0000\n",
      "Processing : 1 / 90\n",
      "0001\n",
      "Processing : 2 / 90\n",
      "0002\n",
      "Processing : 3 / 90\n",
      "0003\n",
      "Processing : 4 / 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/mmdet/datasets/utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0004\n",
      "Processing : 5 / 90\n",
      "0005\n",
      "Processing : 6 / 90\n",
      "0006\n",
      "Processing : 7 / 90\n",
      "0007\n",
      "Processing : 8 / 90\n",
      "0008\n",
      "Processing : 9 / 90\n",
      "0009\n",
      "Processing : 10 / 90\n",
      "0010\n",
      "Processing : 11 / 90\n",
      "0011\n",
      "Processing : 12 / 90\n",
      "0012\n",
      "Processing : 13 / 90\n",
      "0013\n",
      "Processing : 14 / 90\n",
      "0014\n",
      "Processing : 15 / 90\n",
      "0015\n",
      "Processing : 16 / 90\n",
      "0016\n",
      "Processing : 17 / 90\n",
      "0017\n",
      "Processing : 18 / 90\n",
      "0018\n",
      "Processing : 19 / 90\n",
      "0019\n",
      "Processing : 20 / 90\n",
      "0020\n",
      "Processing : 21 / 90\n",
      "0021\n",
      "Processing : 22 / 90\n",
      "0022\n",
      "Processing : 23 / 90\n",
      "0023\n",
      "Processing : 24 / 90\n",
      "0024\n",
      "Processing : 25 / 90\n",
      "0025\n",
      "Processing : 26 / 90\n",
      "0026\n",
      "Processing : 27 / 90\n",
      "0027\n",
      "Processing : 28 / 90\n",
      "0028\n",
      "Processing : 29 / 90\n",
      "0029\n",
      "Processing : 30 / 90\n",
      "0030\n",
      "Processing : 31 / 90\n",
      "0031\n",
      "Processing : 32 / 90\n",
      "0032\n",
      "Processing : 33 / 90\n",
      "0033\n",
      "Processing : 34 / 90\n",
      "0034\n",
      "Processing : 35 / 90\n",
      "0035\n",
      "Processing : 36 / 90\n",
      "0036\n",
      "Processing : 37 / 90\n",
      "0037\n",
      "Processing : 38 / 90\n",
      "0038\n",
      "Processing : 39 / 90\n",
      "0039\n",
      "Processing : 40 / 90\n",
      "0040\n",
      "Processing : 41 / 90\n",
      "0041\n",
      "Processing : 42 / 90\n",
      "0042\n",
      "Processing : 43 / 90\n",
      "0043\n",
      "Processing : 44 / 90\n",
      "0044\n",
      "Processing : 45 / 90\n",
      "0045\n",
      "Processing : 46 / 90\n",
      "0046\n",
      "Processing : 47 / 90\n",
      "0047\n",
      "Processing : 48 / 90\n",
      "0048\n",
      "Processing : 49 / 90\n",
      "0049\n",
      "Processing : 50 / 90\n",
      "0050\n",
      "Processing : 51 / 90\n",
      "0051\n",
      "Processing : 52 / 90\n",
      "0052\n",
      "Processing : 53 / 90\n",
      "0053\n",
      "Processing : 54 / 90\n",
      "0054\n",
      "Processing : 55 / 90\n",
      "0055\n",
      "Processing : 56 / 90\n",
      "0056\n",
      "Processing : 57 / 90\n",
      "0057\n",
      "Processing : 58 / 90\n",
      "0058\n",
      "Processing : 59 / 90\n",
      "0059\n",
      "Processing : 60 / 90\n",
      "0060\n",
      "Processing : 61 / 90\n",
      "0061\n",
      "Processing : 62 / 90\n",
      "0062\n",
      "Processing : 63 / 90\n",
      "0063\n",
      "Processing : 64 / 90\n",
      "0064\n",
      "Processing : 65 / 90\n",
      "0065\n",
      "Processing : 66 / 90\n",
      "0066\n",
      "Processing : 67 / 90\n",
      "0067\n",
      "Processing : 68 / 90\n",
      "0068\n",
      "Processing : 69 / 90\n",
      "0069\n",
      "Processing : 70 / 90\n",
      "0070\n",
      "Processing : 71 / 90\n",
      "0071\n",
      "Processing : 72 / 90\n",
      "0072\n",
      "Processing : 73 / 90\n",
      "0073\n",
      "Processing : 74 / 90\n",
      "0074\n",
      "Processing : 75 / 90\n",
      "0075\n",
      "Processing : 76 / 90\n",
      "0076\n",
      "Processing : 77 / 90\n",
      "0077\n",
      "Processing : 78 / 90\n",
      "0078\n",
      "Processing : 79 / 90\n",
      "0079\n",
      "Processing : 80 / 90\n",
      "0080\n",
      "Processing : 81 / 90\n",
      "0081\n",
      "Processing : 82 / 90\n",
      "0082\n",
      "Processing : 83 / 90\n",
      "0083\n",
      "Processing : 84 / 90\n",
      "0084\n",
      "Processing : 85 / 90\n",
      "0085\n",
      "Processing : 86 / 90\n",
      "0086\n",
      "Processing : 87 / 90\n",
      "0087\n",
      "Processing : 88 / 90\n",
      "0088\n",
      "Processing : 89 / 90\n",
      "0089\n"
     ]
    }
   ],
   "source": [
    "model = init_detector(configs.config_file, configs.weight_file, device=configs.device)\n",
    "confidence_th = 0.9\n",
    "class_id = 2\n",
    "dataset = Dataset(configs.data_dir, configs.result_dir,  fps=configs.fps)\n",
    "\n",
    "total_imgs = len(dataset)\n",
    "detections = {}\n",
    "tags = {}\n",
    "images = {}\n",
    "t2f = []\n",
    "# Inference using the model\n",
    "for idx in range(0, total_imgs):\n",
    "    print(f\"Processing : {idx} / {total_imgs}\")\n",
    "    img_id = f\"{idx:04d}\"\n",
    "    # out_filename = os.path.join(configs.result_dir, f\"{idx}.png\")\n",
    "    img = dataset.get_images(idx)\n",
    "    result = inference_detector(model, img)\n",
    "    class_dets = result[class_id]\n",
    "    scores = class_dets[:, -1]\n",
    "    class_dets = class_dets[scores>confidence_th,:]\n",
    "    print(img_id)\n",
    "    detections[img_id] = class_dets\n",
    "    tags[img_id] = [a[0:4] for a in class_dets]\n",
    "    images[img_id] = img\n",
    "    t2f.append(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Detection:\n",
    "    center: np.ndarray\n",
    "    minc: np.ndarray\n",
    "    maxc: np.ndarray\n",
    "    area: float\n",
    "    reid: Optional[np.ndarray] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Stats:\n",
    "    minc: np.ndarray\n",
    "    maxc: np.ndarray\n",
    "    num_max_det: int\n",
    "\n",
    "\n",
    "def quiet_divide(a, b):\n",
    "    \"\"\"Quiet divide function that does not warn about (0 / 0).\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "        return np.true_divide(a, b)\n",
    "\n",
    "def calc_HS_histogram(image, roi):\n",
    "    roi = [roi.minc[0], roi.minc[1], roi.maxc[0], roi.maxc[1]]\n",
    "    roi = [int(a) for a in roi]\n",
    "    cropped = image[roi[1]:roi[3], roi[0]:roi[2], :]\n",
    "    hsv = cv2.cvtColor(cropped, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hist = cv2.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "    cv2.normalize(hist, hist, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX).flatten()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def calc_bhattacharyya_distance(hist1, hist2):\n",
    "\treturn cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA)\n",
    "\n",
    "\n",
    "def boxiou(det1, det2):\n",
    "    \"\"\"Computes IOU of two rectangles. Taken from\n",
    "    https://github.com/cheind/py-motmetrics/blob/6597e8a4ed398b9f14880fa76de26bc43d230836/motmetrics/distances.py#L64\n",
    "    \"\"\"\n",
    "    a_min, a_max = det1.minc, det1.maxc\n",
    "    b_min, b_max = det2.minc, det2.maxc\n",
    "    # Compute intersection.\n",
    "    i_min = np.maximum(a_min, b_min)\n",
    "    i_max = np.minimum(a_max, b_max)\n",
    "    i_size = np.maximum(i_max - i_min, 0)\n",
    "    i_vol = np.prod(i_size, axis=-1)\n",
    "    # Get volume of union.\n",
    "    a_size = np.maximum(a_max - a_min, 0)\n",
    "    b_size = np.maximum(b_max - b_min, 0)\n",
    "    a_vol = np.prod(a_size, axis=-1)\n",
    "    b_vol = np.prod(b_size, axis=-1)\n",
    "    u_vol = a_vol + b_vol - i_vol\n",
    "    return np.where(\n",
    "        i_vol == 0, np.zeros_like(i_vol, dtype=float), quiet_divide(i_vol, u_vol)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0000': [0, 1, 2], '0001': [0, 1, 2], '0002': [1, 0, 2], '0003': [1, 0, 2], '0004': [0, 1, 2], '0005': [0, 1, 2], '0006': [1, 0, 2], '0007': [1, 0, 2], '0008': [1, 0, 2], '0009': [1, 0, 2], '0010': [0, 1, 2], '0011': [1, 0, 2], '0012': [0, 2, 1], '0013': [1, 2, 0], '0014': [1, 0, 2], '0015': [1, 0, 2], '0016': [1, 0, 2], '0017': [1, 0, 2], '0018': [1, 0, 2], '0019': [1, 0, 2], '0020': [0, 2, 1], '0021': [1, 0, 2], '0022': [1, 0, 2], '0023': [1, 2, 0], '0024': [0, 1, 2], '0025': [2, 1, 0], '0026': [1, 2], '0027': [1, 2, 0], '0028': [1, 2, 0], '0029': [2, 1, 0], '0030': [1, 2], '0031': [1, 2, 0], '0032': [1, 2], '0033': [1, 2], '0034': [2, 1, 3], '0035': [1, 2, 3], '0036': [1, 2, 3], '0037': [1, 2], '0038': [1, 2], '0039': [1, 2, 3], '0040': [1, 3, 2, 4, -1], '0041': [1, 2, 3], '0042': [1, 2, 3, 4], '0043': [1, 2, 4], '0044': [1, 3, 2, 4], '0045': [1, 3, 4, 2], '0046': [1, 3, 2, 4], '0047': [1, 2, 3], '0048': [2, 3, 1], '0049': [1, 3, 2, 4], '0050': [1, 3, 2], '0051': [1, 2, 3, 4], '0052': [1, 2, 3, 4], '0053': [1, 2, 3, 4], '0054': [1, 4, 2, 3], '0055': [1, 4, 3, 2], '0056': [1, 3, 4, 2], '0057': [1, 4, 2, 5], '0058': [1, 4, 2, 3, 5], '0059': [2, 4, 1], '0060': [1, 2, 5, 4], '0061': [2, 1, 4, 5, 3], '0062': [2, 1, 4, 3], '0063': [1, 4, 2, 3], '0064': [1, 2, -1, 4, 3], '0065': [1, 4, 3, 2, 5], '0066': [1, 4, 2, 5], '0067': [2, 1, 4], '0068': [1, 4, 2, 5], '0069': [2, 1, 4, 5, -1], '0070': [2, 4, 1, 5], '0071': [2, 1, 4, 5], '0072': [4, 2, 1, 5], '0073': [5, 4, 2, 1, 6], '0074': [5, 1, 2, 4, 6], '0075': [2, 1, 4, 6, 5], '0076': [2, 1, 4, 6, 5], '0077': [2, 4, 1, 6, 5], '0078': [4, 2, 1, 5, 6], '0079': [4, 2, 1, 5, 6], '0080': [1, 4, 2, 5], '0081': [4, 1, 2], '0082': [1, 2, 4, 6], '0083': [4, 2, 1], '0084': [1, 4, 2, 6], '0085': [1, 4, 2, 6], '0086': [4, 1, 2, 6], '0087': [1, 4, 2], '0088': [1, 4, 2], '0089': [4, 2, 1, 6]} [{'idx': 0, 'start': '0000', 'end': '0031'}, {'idx': 1, 'start': '0000', 'end': '0089'}, {'idx': 2, 'start': '0000', 'end': '0089'}, {'idx': 3, 'start': '0034', 'end': '0065'}, {'idx': 4, 'start': '0040', 'end': '0089'}, {'idx': 5, 'start': '0057', 'end': '0080'}, {'idx': 6, 'start': '0073', 'end': '0089'}] Stats(minc=array([374.02758789, 154.36080933]), maxc=array([1677.45043945, 1027.36425781]), num_max_det=5)\n"
     ]
    }
   ],
   "source": [
    "timeseries = []\n",
    "fnames = []\n",
    "\n",
    "\n",
    "stats = Stats(minc=np.array([1e3] * 2), maxc=np.array([-1e3] * 2), num_max_det=0)\n",
    "for t, (fname, objs) in enumerate(detections.items()):\n",
    "    fnames.append(fname)\n",
    "    tdata = []\n",
    "\n",
    "    for oidx, obj in enumerate(objs):\n",
    "        minc = np.array([obj[0], obj[1]])\n",
    "        maxc = np.array([obj[2], obj[3]])\n",
    "        c = (minc + maxc) * 0.5\n",
    "        area = (maxc[0] - minc[0]) * (maxc[1] - minc[1])\n",
    "\n",
    "        tdata.append(Detection(c, minc, maxc, area))\n",
    "        stats.minc = np.minimum(stats.minc, minc)\n",
    "        stats.maxc = np.maximum(stats.maxc, maxc)\n",
    "    timeseries.append(tdata)\n",
    "    stats.num_max_det = max(stats.num_max_det, len(tdata))\n",
    "\n",
    "class GraphCosts(gflow.StandardGraphCosts):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            penter=1e-2,\n",
    "            pexit=1e-4,\n",
    "            beta=2e-2,\n",
    "            max_obs_time=len(timeseries) - 1,\n",
    "        )\n",
    "\n",
    "    def transition_cost(self, x: gflow.FlowNode, y: gflow.FlowNode) -> float:\n",
    "        \"\"\"Log-probability of pairing xi(t-1) with xj(t).\n",
    "        Modelled by intersection over union downweighted by an\n",
    "        exponential decreasing probability on the time-difference.\n",
    "        \"\"\"\n",
    "        iou_logprob = np.log(boxiou(x.obs, y.obs) + 1e-8)\n",
    "        tdiff = y.time_index - x.time_index\n",
    "        tlogprob = scipy.stats.expon.logpdf(\n",
    "            tdiff, loc=1.0, scale=1 / 1.0\n",
    "        )\n",
    "        hist1 = calc_HS_histogram(images[t2f[x.time_index]], x.obs)\n",
    "        hist2 = calc_HS_histogram(images[t2f[y.time_index]], x.obs)\n",
    "        prob_color = 1.0 - calc_bhattacharyya_distance(hist1, hist2)\n",
    "        return -(iou_logprob)\n",
    "\n",
    "flowgraph = gflow.build_flow_graph(\n",
    "timeseries, GraphCosts(), num_skip_layers=3, cost_scale=1e4, max_cost=3e3\n",
    ")\n",
    "flowdict, _, _ = gflow.solve(flowgraph, (1, 20))\n",
    "traj = gflow.find_trajectories(flowdict)\n",
    "obs_to_traj = gflow.label_observations(timeseries, traj)\n",
    "traj_info = [\n",
    "    {\"idx\": tidx, \"start\": fnames[t[0].time_index], \"end\": fnames[t[-1].time_index]}\n",
    "    for tidx, t in enumerate(traj)\n",
    "]\n",
    "# Use filenames instead of time indices\n",
    "obs_to_traj = {fname: ids for fname, ids in zip(fnames, obs_to_traj)}\n",
    "print(obs_to_traj, traj_info, stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.visulaizations import draw_bb\n",
    "\n",
    "\n",
    "palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
    "def compute_color_for_labels(label):\n",
    "    \"\"\"\n",
    "    Simple function that adds fixed color depending on the class\n",
    "    \"\"\"\n",
    "    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
    "    return tuple(color)\n",
    "def draw_boxes(img, bbox, identities=None, offset=(0,0)):\n",
    "    for i,box in enumerate(bbox):\n",
    "        x1,y1,x2,y2 = [int(i) for i in box]\n",
    "        x1 += offset[0]\n",
    "        x2 += offset[0]\n",
    "        y1 += offset[1]\n",
    "        y2 += offset[1]\n",
    "        # box text and bar\n",
    "        id = int(identities[i]) if identities is not None else 0    \n",
    "        color = compute_color_for_labels(id)\n",
    "        label = '{}{:d}'.format(\"\", id)\n",
    "        t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 2 , 2)[0]\n",
    "        cv2.rectangle(img,(x1, y1),(x2,y2),color,3)\n",
    "        cv2.rectangle(img,(x1, y1),(x1+t_size[0]+3,y1+t_size[1]+4), color,-1)\n",
    "        cv2.putText(img,label,(x1,y1+t_size[1]+4), cv2.FONT_HERSHEY_PLAIN, 2, [255,255,255], 2)\n",
    "    return img\n",
    "\n",
    "RESULT_DIR = \"../../results/mcftracker\"\n",
    "\n",
    "# 書き込み設定\n",
    "fourcc = cv2.VideoWriter_fourcc('m','p','4', 'v')\n",
    "im_width = img.shape[1]\n",
    "im_height = img.shape[0]\n",
    "fps = 15\n",
    "\n",
    "save_video_path = f\"{RESULT_DIR}/results.mp4\"\n",
    "\n",
    "video = cv2.VideoWriter(filename=save_video_path,\n",
    "                        fourcc=fourcc,\n",
    "                        fps=fps,\n",
    "                        frameSize=(int(im_width),int(im_height)))\n",
    "\n",
    "for fname in images.keys():\n",
    "    ids = obs_to_traj[fname]\n",
    "    bbs = detections[fname]\n",
    "\n",
    "    img = images[fname]\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    overlayed = draw_boxes(img, [[bb[0], bb[1], bb[2], bb[3]] for bb in bbs], ids)\n",
    "    video.write(overlayed)\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
