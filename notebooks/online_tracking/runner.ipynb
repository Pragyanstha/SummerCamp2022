{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Data paths\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Path追加\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import configargparse\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from args import get_config\n",
    "from data import Dataset\n",
    "from common.visulaizations import draw_bb\n",
    "\n",
    "configs = get_config(\"-c ../../configs/deepsort_notebook.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../../weights/latest.pth\n",
      "Processing : 0 / 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/mmdet/datasets/utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing : 1 / 35\n",
      "[]\n",
      "Processing : 2 / 35\n",
      "[[659 532 759 645   1]\n",
      " [729 821 898 974   2]]\n",
      "Processing : 3 / 35\n",
      "[[660 545 767 667   1]\n",
      " [690 818 873 981   2]]\n",
      "Processing : 4 / 35\n",
      "[[ 662  570  774  701    1]\n",
      " [ 645  806  865 1001    2]]\n",
      "Processing : 5 / 35\n",
      "[[ 654  593  779  741    1]\n",
      " [ 605  786  858 1013    2]]\n",
      "Processing : 6 / 35\n",
      "[[ 647  630  778  785    1]\n",
      " [ 587  769  861 1021    2]]\n",
      "Processing : 7 / 35\n",
      "[[ 638  660  775  823    1]\n",
      " [ 597  764  871 1023    2]]\n",
      "Processing : 8 / 35\n",
      "[[ 626  689  770  859    1]\n",
      " [ 606  763  875 1024    2]]\n",
      "Processing : 9 / 35\n",
      "[[ 622  710  772  887    1]\n",
      " [ 613  759  879 1022    2]]\n",
      "Processing : 10 / 35\n",
      "[[ 600  740  762  937    1]\n",
      " [ 626  752  888 1017    2]]\n",
      "Processing : 11 / 35\n",
      "[[ 602  752  762  951    1]\n",
      " [ 637  760  889 1021    2]]\n",
      "Processing : 12 / 35\n",
      "[[ 612  749  767  946    1]\n",
      " [ 649  774  879 1018    2]]\n",
      "Processing : 13 / 35\n",
      "[[ 618  739  768  934    1]\n",
      " [ 650  768  876 1017    2]]\n",
      "Processing : 14 / 35\n",
      "[[ 626  740  771  930    1]\n",
      " [ 658  763  878 1016    2]]\n",
      "Processing : 15 / 35\n",
      "[[ 657  763  784  930    1]\n",
      " [ 674  755  889 1015    2]]\n",
      "Processing : 16 / 35\n",
      "[[ 658  778  787  948    1]\n",
      " [ 690  752  896 1014    2]]\n",
      "Processing : 17 / 35\n",
      "[[ 710  756  903 1015    2]]\n",
      "Processing : 18 / 35\n",
      "[[ 728  753  915 1017    2]]\n",
      "Processing : 19 / 35\n",
      "[[ 746  747  927 1010    2]\n",
      " [ 829  732  982  841    3]]\n",
      "Processing : 20 / 35\n",
      "[[ 760  746  932 1004    2]\n",
      " [ 859  723  991  815    3]]\n",
      "Processing : 21 / 35\n",
      "[[ 777  756  937 1002    2]\n",
      " [ 873  715  995  800    3]]\n",
      "Processing : 22 / 35\n",
      "[[ 788  757  948 1007    2]\n",
      " [ 877  712  995  794    3]]\n",
      "Processing : 23 / 35\n",
      "[[ 799  757  962 1012    2]\n",
      " [ 896  707 1015  790    3]]\n",
      "Processing : 24 / 35\n",
      "[[ 805  753  975 1018    2]\n",
      " [ 913  698 1030  781    3]]\n",
      "Processing : 25 / 35\n",
      "[[ 812  754  980 1015    2]\n",
      " [ 919  692 1036  777    3]]\n",
      "Processing : 26 / 35\n",
      "[[ 816  748  988 1015    2]\n",
      " [ 922  688 1037  772    3]]\n",
      "Processing : 27 / 35\n",
      "[[ 822  745  993 1010    2]\n",
      " [ 923  684 1035  767    3]]\n",
      "Processing : 28 / 35\n",
      "[[ 827  744  994 1004    2]\n",
      " [ 924  679 1036  764    3]]\n",
      "Processing : 29 / 35\n",
      "[[ 828  738  996 1003    2]\n",
      " [ 925  676 1033  759    3]]\n",
      "Processing : 30 / 35\n",
      "[[ 822  735  988  998    2]\n",
      " [ 926  672 1033  757    3]]\n",
      "Processing : 31 / 35\n",
      "[[ 817  734  980  996    2]\n",
      " [ 931  671 1036  755    3]]\n",
      "Processing : 32 / 35\n",
      "[[ 813  737  974  998    2]\n",
      " [ 933  671 1036  755    3]]\n",
      "Processing : 33 / 35\n",
      "[[ 815  729  977  991    2]\n",
      " [ 936  671 1036  756    3]]\n",
      "Processing : 34 / 35\n",
      "[[ 813  724  977  990    2]\n",
      " [ 936  670 1035  756    3]]\n"
     ]
    }
   ],
   "source": [
    "from mmdetds import MMdetDS\n",
    "from deepsort import DeepSort\n",
    "\n",
    "REID_CKPT = \"../..//weights/ckpt.t7\"\n",
    "MAX_DIST = 0.2\n",
    "MIN_CONFIDENCE = 0.3\n",
    "NMS_MAX_OVERLAP = 0.5\n",
    "MAX_IOU_DISTANCE = 0.7\n",
    "MAX_AGE = 70\n",
    "N_INIT = 3\n",
    "NN_BUDGET = 100\n",
    "  \n",
    "\n",
    "class_id = 2\n",
    "dataset = Dataset(configs.data_dir, configs.result_dir,  fps=configs.fps)\n",
    "\n",
    "total_imgs = len(dataset)\n",
    "# detectionモデルのインスタンス化\n",
    "detector = MMdetDS(configs=configs)\n",
    "\n",
    "# trackingモデルのインスタンス化\n",
    "deepsort = DeepSort(model_path=REID_CKPT,\n",
    "                    max_dist=MAX_DIST,\n",
    "                    min_confidence=MIN_CONFIDENCE,\n",
    "                    nms_max_overlap=NMS_MAX_OVERLAP,\n",
    "                    max_iou_distance=MAX_IOU_DISTANCE, \n",
    "                    max_age=MAX_AGE,\n",
    "                    n_init=N_INIT,\n",
    "                    nn_budget=NN_BUDGET,\n",
    "                    device=configs.device)\n",
    "\n",
    "# Inference using the model\n",
    "for idx in range(0, total_imgs):\n",
    "    print(f\"Processing : {idx} / {total_imgs}\")\n",
    "    img_id = f\"{idx:04d}\"\n",
    "    # out_filename = os.path.join(configs.result_dir, f\"{idx}.png\")\n",
    "    img = dataset.get_images(idx)\n",
    "\n",
    "    # detection\n",
    "    bbox_xywh, cls_conf, cls_ids, bbox_result = detector(img)\n",
    "    bbox_xywh = bbox_xywh[cls_ids == class_id]\n",
    "    cls_conf = cls_conf[cls_ids == class_id]\n",
    "\n",
    "    # tracking\n",
    "    outputs = deepsort.update(bbox_xywh, cls_conf, img)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
